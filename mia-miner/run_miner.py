#!/usr/bin/env python3
"""
MIA GPU Miner Client
Polls the MIA backend for jobs and processes them using GPU inference
"""

import os
import sys
import time
import json
import logging
import requests
from datetime import datetime
from typing import Dict, Optional, Any
import random
import signal
from fallback_manager import FallbackManager

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(sys.stdout)
    ]
)
logger = logging.getLogger('mia-miner')

class MIAMiner:
    def __init__(self):
        self.api_url = os.environ.get('MIA_API_URL', 'https://mia-backend-production.up.railway.app').rstrip('/')
        self.miner_name = os.environ.get('MINER_NAME', 'gpu-miner-001')
        self.poll_interval = int(os.environ.get('POLL_INTERVAL', '5'))
        self.miner_id = None
        self.auth_key = None
        
        # Initialize fallback manager
        self.fallback_manager = FallbackManager(self.miner_name, self.api_url)
        self.fallback_idle_threshold = 10  # Start fallback after 10 seconds of no jobs
        self.last_job_time = time.time()
        self.fallback_active = False
        
        logger.info(f"MIA Miner initialized")
        logger.info(f"API URL: {self.api_url}")
        logger.info(f"Miner Name: {self.miner_name}")
        logger.info(f"Poll Interval: {self.poll_interval}s")
        
        # Register miner on startup
        self.register_miner()
    
    def register_miner(self):
        """Register this miner with the backend"""
        try:
            response = requests.post(
                f"{self.api_url}/register_miner",
                json={"name": self.miner_name},
                timeout=10
            )
            
            if response.status_code == 200:
                data = response.json()
                self.miner_id = data.get('miner_id')
                self.auth_key = data.get('auth_key')
                logger.info(f"Miner registered successfully. ID: {self.miner_id}")
            else:
                logger.error(f"Failed to register miner: {response.status_code} - {response.text}")
        except Exception as e:
            logger.error(f"Error registering miner: {e}")
    
    def simulate_inference(self, prompt: str, max_tokens: int = 500) -> Dict[str, Any]:
        """
        Simulate model inference (to be replaced with actual Mixtral later)
        """
        # Simulate processing time (1-3 seconds)
        processing_time = random.uniform(1.0, 3.0)
        time.sleep(processing_time)
        
        # Generate dummy response
        responses = [
            "This is a simulated response from the MIA miner. In production, this would be generated by Mixtral.",
            "I'm processing your request on a GPU. This is a test response.",
            "MIA miner here! Your job has been processed successfully.",
            f"Response to '{prompt[:50]}...' - Processing complete!",
            "GPU inference simulation complete. Real Mixtral integration coming soon!"
        ]
        
        response_text = random.choice(responses)
        
        # Simulate token count (roughly 1.3 tokens per word)
        word_count = len(response_text.split())
        output_tokens = int(word_count * 1.3)
        
        return {
            "output": response_text,
            "output_tokens": output_tokens,
            "processing_time": processing_time,
            "gpu_utilization": random.randint(70, 95)  # Simulated GPU usage
        }
    
    def process_mia_job(self, job: Dict[str, Any]) -> bool:
        """Process a MIA job and submit the result"""
        job_id = job.get('job_id')
        prompt = job.get('prompt', '')
        context = job.get('context', '')
        session_id = job.get('session_id')
        
        logger.info(f"Processing MIA job {job_id}")
        
        try:
            # Simulate inference
            full_prompt = f"{context}\n{prompt}" if context else prompt
            result = self.simulate_inference(full_prompt)
            
            # Submit result
            response = requests.post(
                f"{self.api_url}/job/result",
                json={
                    "job_id": job_id,
                    "session_id": session_id,
                    "output": result["output"],
                    "miner_id": self.miner_id
                },
                timeout=10
            )
            
            if response.status_code == 200:
                logger.info(f"MIA job {job_id} completed successfully. Tokens: {result['output_tokens']}")
                return True
            else:
                logger.error(f"Failed to submit MIA job result: {response.status_code} - {response.text}")
                return False
                
        except Exception as e:
            logger.error(f"Error processing MIA job {job_id}: {e}")
            return False
    
    def process_idle_job(self, job: Dict[str, Any]) -> bool:
        """Process an idle job and submit the result"""
        job_id = job.get('job_id')
        prompt = job.get('prompt', '')
        max_tokens = job.get('max_tokens', 500)
        
        logger.info(f"Processing idle job {job_id}")
        
        try:
            # Simulate inference
            result = self.simulate_inference(prompt, max_tokens)
            
            # Calculate simulated earnings (matching backend pricing)
            tokens_in_thousands = result["output_tokens"] / 1000
            revenue_usd = round(tokens_in_thousands * 0.001, 6)  # $0.001 per 1K tokens
            
            # Submit result
            response = requests.post(
                f"{self.api_url}/idle-job/result",
                json={
                    "job_id": job_id,
                    "output": result["output"],
                    "output_tokens": result["output_tokens"],
                    "usd_earned": revenue_usd,
                    "runpod_job_id": f"sim-{job_id}-{int(time.time())}"
                },
                timeout=10
            )
            
            if response.status_code == 200:
                logger.info(f"Idle job {job_id} completed. Tokens: {result['output_tokens']}, Revenue: ${revenue_usd}")
                return True
            else:
                logger.error(f"Failed to submit idle job result: {response.status_code} - {response.text}")
                return False
                
        except Exception as e:
            logger.error(f"Error processing idle job {job_id}: {e}")
            return False
    
    def poll_for_jobs(self):
        """Main polling loop"""
        logger.info("Starting job polling loop...")
        consecutive_errors = 0
        
        while True:
            try:
                # First, try to get a MIA job
                response = requests.get(
                    f"{self.api_url}/job/next",
                    params={"miner_id": self.miner_id} if self.miner_id else {},
                    timeout=10
                )
                
                if response.status_code == 200:
                    job = response.json()
                    
                    if job.get('job_id'):
                        consecutive_errors = 0
                        self.last_job_time = time.time()
                        
                        # Stop fallback if running
                        if self.fallback_active:
                            self.fallback_manager.stop_fallback()
                            self.fallback_active = False
                        
                        self.process_mia_job(job)
                        continue  # Skip sleep to process next job quickly
                    else:
                        # No MIA jobs, try idle jobs
                        idle_response = requests.get(
                            f"{self.api_url}/idle-job/next",
                            timeout=10
                        )
                        
                        if idle_response.status_code == 200:
                            idle_job = idle_response.json()
                            
                            if idle_job.get('job_id'):
                                consecutive_errors = 0
                                self.last_job_time = time.time()
                                
                                # Stop fallback if running
                                if self.fallback_active:
                                    self.fallback_manager.stop_fallback()
                                    self.fallback_active = False
                                
                                self.process_idle_job(idle_job)
                                continue  # Skip sleep to process next job quickly
                            else:
                                # No jobs available - check if we should start fallback
                                time_since_last_job = time.time() - self.last_job_time
                                
                                if time_since_last_job > self.fallback_idle_threshold and not self.fallback_active:
                                    self.fallback_manager.start_fallback()
                                    self.fallback_active = True
                                
                                logger.debug("No jobs available")
                else:
                    consecutive_errors += 1
                    logger.warning(f"Failed to poll for jobs: {response.status_code}")
                
                # Sleep before next poll
                time.sleep(self.poll_interval)
                
                # Exponential backoff on errors
                if consecutive_errors > 5:
                    sleep_time = min(60, self.poll_interval * (2 ** (consecutive_errors - 5)))
                    logger.warning(f"Multiple errors detected, backing off for {sleep_time}s")
                    time.sleep(sleep_time)
                    
            except requests.exceptions.RequestException as e:
                consecutive_errors += 1
                logger.error(f"Network error polling for jobs: {e}")
                time.sleep(self.poll_interval * 2)
            except KeyboardInterrupt:
                logger.info("Miner shutdown requested")
                break
            except Exception as e:
                consecutive_errors += 1
                logger.error(f"Unexpected error: {e}")
                time.sleep(self.poll_interval)
        
        # Cleanup fallback on exit
        if self.fallback_active:
            self.fallback_manager.stop_fallback()
        
        self.fallback_manager.cleanup()
        logger.info("Miner stopped")

def check_gpu():
    """Check if GPU is available (basic check)"""
    try:
        # Try to check NVIDIA GPU
        import subprocess
        result = subprocess.run(['nvidia-smi'], capture_output=True, text=True)
        if result.returncode == 0:
            logger.info("NVIDIA GPU detected")
            return True
        else:
            logger.warning("No NVIDIA GPU detected - running in CPU mode")
            return False
    except Exception:
        logger.warning("nvidia-smi not found - running in CPU mode")
        return False

def main():
    """Main entry point"""
    logger.info("=== MIA GPU Miner Starting ===")
    
    # Check GPU availability
    has_gpu = check_gpu()
    
    # Verify required environment variables
    if not os.environ.get('MIA_API_URL'):
        logger.warning("MIA_API_URL not set, using default: https://mia-backend-production.up.railway.app")
    
    # Create and run miner
    miner = MIAMiner()
    
    try:
        miner.poll_for_jobs()
    except Exception as e:
        logger.error(f"Fatal error: {e}")
        sys.exit(1)

def signal_handler(signum, frame):
    """Handle shutdown signals"""
    logger.info("Shutdown signal received")
    sys.exit(0)

if __name__ == "__main__":
    # Set up signal handlers
    signal.signal(signal.SIGINT, signal_handler)
    signal.signal(signal.SIGTERM, signal_handler)
    
    main()