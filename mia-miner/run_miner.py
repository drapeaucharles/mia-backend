#!/usr/bin/env python3
"""
MIA GPU Miner Client
Polls the MIA backend for jobs and processes them using GPU inference
"""

import os
import sys
import time
import json
import logging
import requests
from datetime import datetime
from typing import Dict, Optional, Any
import random

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(sys.stdout)
    ]
)
logger = logging.getLogger('mia-miner')

class MIAMiner:
    def __init__(self):
        self.api_url = os.environ.get('MIA_API_URL', 'https://mia-backend-production.up.railway.app').rstrip('/')
        self.miner_name = os.environ.get('MINER_NAME', 'gpu-miner-001')
        self.poll_interval = int(os.environ.get('POLL_INTERVAL', '5'))
        self.miner_id = None
        self.auth_key = None
        
        logger.info(f"MIA Miner initialized")
        logger.info(f"API URL: {self.api_url}")
        logger.info(f"Miner Name: {self.miner_name}")
        logger.info(f"Poll Interval: {self.poll_interval}s")
        
        # Register miner on startup
        self.register_miner()
    
    def register_miner(self):
        """Register this miner with the backend"""
        try:
            response = requests.post(
                f"{self.api_url}/register_miner",
                json={"name": self.miner_name},
                timeout=10
            )
            
            if response.status_code == 200:
                data = response.json()
                self.miner_id = data.get('miner_id')
                self.auth_key = data.get('auth_key')
                logger.info(f"Miner registered successfully. ID: {self.miner_id}")
            else:
                logger.error(f"Failed to register miner: {response.status_code} - {response.text}")
        except Exception as e:
            logger.error(f"Error registering miner: {e}")
    
    def simulate_inference(self, prompt: str, max_tokens: int = 500) -> Dict[str, Any]:
        """
        Simulate model inference (to be replaced with actual Mixtral later)
        """
        # Simulate processing time (1-3 seconds)
        processing_time = random.uniform(1.0, 3.0)
        time.sleep(processing_time)
        
        # Generate dummy response
        responses = [
            "This is a simulated response from the MIA miner. In production, this would be generated by Mixtral.",
            "I'm processing your request on a GPU. This is a test response.",
            "MIA miner here! Your job has been processed successfully.",
            f"Response to '{prompt[:50]}...' - Processing complete!",
            "GPU inference simulation complete. Real Mixtral integration coming soon!"
        ]
        
        response_text = random.choice(responses)
        
        # Simulate token count (roughly 1.3 tokens per word)
        word_count = len(response_text.split())
        output_tokens = int(word_count * 1.3)
        
        return {
            "output": response_text,
            "output_tokens": output_tokens,
            "processing_time": processing_time,
            "gpu_utilization": random.randint(70, 95)  # Simulated GPU usage
        }
    
    def process_mia_job(self, job: Dict[str, Any]) -> bool:
        """Process a MIA job and submit the result"""
        job_id = job.get('job_id')
        prompt = job.get('prompt', '')
        context = job.get('context', '')
        session_id = job.get('session_id')
        
        logger.info(f"Processing MIA job {job_id}")
        
        try:
            # Simulate inference
            full_prompt = f"{context}\n{prompt}" if context else prompt
            result = self.simulate_inference(full_prompt)
            
            # Submit result
            response = requests.post(
                f"{self.api_url}/job/result",
                json={
                    "job_id": job_id,
                    "session_id": session_id,
                    "output": result["output"],
                    "miner_id": self.miner_id
                },
                timeout=10
            )
            
            if response.status_code == 200:
                logger.info(f"MIA job {job_id} completed successfully. Tokens: {result['output_tokens']}")
                return True
            else:
                logger.error(f"Failed to submit MIA job result: {response.status_code} - {response.text}")
                return False
                
        except Exception as e:
            logger.error(f"Error processing MIA job {job_id}: {e}")
            return False
    
    def process_idle_job(self, job: Dict[str, Any]) -> bool:
        """Process an idle job and submit the result"""
        job_id = job.get('job_id')
        prompt = job.get('prompt', '')
        max_tokens = job.get('max_tokens', 500)
        
        logger.info(f"Processing idle job {job_id}")
        
        try:
            # Simulate inference
            result = self.simulate_inference(prompt, max_tokens)
            
            # Calculate simulated earnings (matching backend pricing)
            tokens_in_thousands = result["output_tokens"] / 1000
            revenue_usd = round(tokens_in_thousands * 0.001, 6)  # $0.001 per 1K tokens
            
            # Submit result
            response = requests.post(
                f"{self.api_url}/idle-job/result",
                json={
                    "job_id": job_id,
                    "output": result["output"],
                    "output_tokens": result["output_tokens"],
                    "usd_earned": revenue_usd,
                    "runpod_job_id": f"sim-{job_id}-{int(time.time())}"
                },
                timeout=10
            )
            
            if response.status_code == 200:
                logger.info(f"Idle job {job_id} completed. Tokens: {result['output_tokens']}, Revenue: ${revenue_usd}")
                return True
            else:
                logger.error(f"Failed to submit idle job result: {response.status_code} - {response.text}")
                return False
                
        except Exception as e:
            logger.error(f"Error processing idle job {job_id}: {e}")
            return False
    
    def poll_for_jobs(self):
        """Main polling loop"""
        logger.info("Starting job polling loop...")
        consecutive_errors = 0
        
        while True:
            try:
                # First, try to get a MIA job
                response = requests.get(
                    f"{self.api_url}/job/next",
                    params={"miner_id": self.miner_id} if self.miner_id else {},
                    timeout=10
                )
                
                if response.status_code == 200:
                    job = response.json()
                    
                    if job.get('job_id'):
                        consecutive_errors = 0
                        self.process_mia_job(job)
                        continue  # Skip sleep to process next job quickly
                    else:
                        # No MIA jobs, try idle jobs
                        idle_response = requests.get(
                            f"{self.api_url}/idle-job/next",
                            timeout=10
                        )
                        
                        if idle_response.status_code == 200:
                            idle_job = idle_response.json()
                            
                            if idle_job.get('job_id'):
                                consecutive_errors = 0
                                self.process_idle_job(idle_job)
                                continue  # Skip sleep to process next job quickly
                            else:
                                logger.debug("No jobs available")
                else:
                    consecutive_errors += 1
                    logger.warning(f"Failed to poll for jobs: {response.status_code}")
                
                # Sleep before next poll
                time.sleep(self.poll_interval)
                
                # Exponential backoff on errors
                if consecutive_errors > 5:
                    sleep_time = min(60, self.poll_interval * (2 ** (consecutive_errors - 5)))
                    logger.warning(f"Multiple errors detected, backing off for {sleep_time}s")
                    time.sleep(sleep_time)
                    
            except requests.exceptions.RequestException as e:
                consecutive_errors += 1
                logger.error(f"Network error polling for jobs: {e}")
                time.sleep(self.poll_interval * 2)
            except KeyboardInterrupt:
                logger.info("Miner shutdown requested")
                break
            except Exception as e:
                consecutive_errors += 1
                logger.error(f"Unexpected error: {e}")
                time.sleep(self.poll_interval)
        
        logger.info("Miner stopped")

def check_gpu():
    """Check if GPU is available (basic check)"""
    try:
        # Try to check NVIDIA GPU
        import subprocess
        result = subprocess.run(['nvidia-smi'], capture_output=True, text=True)
        if result.returncode == 0:
            logger.info("NVIDIA GPU detected")
            return True
        else:
            logger.warning("No NVIDIA GPU detected - running in CPU mode")
            return False
    except Exception:
        logger.warning("nvidia-smi not found - running in CPU mode")
        return False

def main():
    """Main entry point"""
    logger.info("=== MIA GPU Miner Starting ===")
    
    # Check GPU availability
    has_gpu = check_gpu()
    
    # Verify required environment variables
    if not os.environ.get('MIA_API_URL'):
        logger.warning("MIA_API_URL not set, using default: https://mia-backend-production.up.railway.app")
    
    # Create and run miner
    miner = MIAMiner()
    
    try:
        miner.poll_for_jobs()
    except Exception as e:
        logger.error(f"Fatal error: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()